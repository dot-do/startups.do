---
name: CleanSight QA
slug: cleansight
service:
  title: Photo/Video QA Audits with Automatic Scoring
  description: >-
    Vision-based quality checks from cleaner or client uploads; flags missed
    tasks and compiles QA reports.
  targetUsers:
    - Ops managers
    - Account managers
    - Franchise owners
  triggers:
    - Post-service photo upload via QR code link
    - Random audit schedule
    - Client-submitted images/videos
  inputs:
    - Timestamped/geotagged images or short videos
    - Location checklist/SOPs
    - Room list and priority areas
  steps:
    - Collect media via mobile web form or WhatsApp
    - 'Detect cleanliness indicators (streaks, trash, dust)'
    - Score against checklist; highlight misses
    - Escalate low-confidence items to reviewer
    - Send report to client and create rework ticket
  tools:
    - OpenAI Vision/AWS Rekognition
    - Jotform/Typeform mobile forms with QR
    - Slack/Email for alerts
    - Asana/Trello for rework tickets
    - Google Drive for media storage
  outputs:
    - QA scorecard and heatmap
    - Before/after galleries
    - Rework task list with due dates
    - Trend dashboard by site/crew
  pricingModel:
    - Per site per month
    - Per audit bundle pricing
  humanInLoop: true
  feasibility:
    remoteOnLaptop: 9
    modelCapability: 7
    overall: 8
  risks:
    - Poor lighting/angles reduce accuracy
    - Privacy concerns with photos
    - False positives/negatives require review
  dependencies:
    - Client consent for media capture
    - Site checklists/SOPs
    - Storage policy for images
leanCanvas:
  problem:
    - >-
      Manual janitorial QA is time-consuming and inconsistent; supervisors spend
      20–40% of time traveling to sites for spot checks.
    - >-
      Photos/videos are often collected but not structured—no objective scoring,
      versioning, or trend analysis.
    - >-
      Client complaints are reactive; issues are found days later, risking SLA
      penalties and contract churn.
    - 'Fraud risk: recycled/stock photos and backdated uploads undermine trust.'
    - >-
      Inconsistent checklists across sites lead to uneven quality and unclear
      accountability.
    - >-
      No quantified link between QA activities and outcomes (complaints, rework,
      renewals).
    - >-
      Existing QA tools rely on manual inspections and forms; adoption drops due
      to effort and subjectivity.
    - >-
      Facilities require proof-of-service artifacts for compliance (e.g.,
      healthcare, education) but lack credible, auditable evidence.
  solution:
    - >-
      Simple capture: cleaners or clients upload photos/videos via mobile app or
      existing WFM app integration; automatic timestamp, geofence, and site ID.
    - >-
      AI scoring: computer vision detects completion of checklist items (e.g.,
      empty bins, streak-free mirrors, stocked dispensers, floor condition),
      assigns weighted scores, and highlights misses with confidence levels.
    - >-
      Issue workflow: auto-create corrective tasks with location, media
      evidence, and due dates; notify supervisors; verify fixes with follow-up
      media.
    - >-
      Fraud safeguards: EXIF verification, dynamic QR/geo tokens on-site,
      similarity checks to prevent recycled media, and optional liveness prompts
      for video.
    - >-
      Client-ready QA reports: branded PDFs/links summarizing scores, issues,
      SLA adherence, and trends; export to client portals.
    - >-
      Analytics: site-, client-, and cleaner-level trend dashboards (compliance,
      issue recurrence, root causes, cost of rework).
    - >-
      Human-in-the-loop review: optional secondary validation on low-confidence
      detections for critical sites (healthcare, food).
    - >-
      APIs/Integrations: plug into TEAM Software/WorkWave, Swept, Aspire,
      Jobber, OrangeQC, iAuditor, and CMMS (UpKeep, Fiix).
  uniqueValueProp: >-
    Automated, objective QA from everyday photos/videos. CleanSight QA turns
    uploads into instant, auditable scores and issue flags—cutting supervisor
    site visits by up to 30%, reducing complaint rates by 20–40%, and producing
    client-ready reports that protect revenue and renewals.
  unfairAdvantage: >-
    A growing, proprietary, real-world dataset of janitorial scenarios across
    industries plus calibrated scoring rubrics tied to SLAs—continuously
    improved via human-in-the-loop feedback and enterprise integrations. This
    data and integration moat yields superior model accuracy, faster ROI proofs,
    and stickiness embedded in customers’ daily workflows.
  customerSegments:
    - >-
      Mid-market janitorial service providers (50–500 cleaners) with multi-site
      contracts (offices, schools, healthcare, retail).
    - >-
      Enterprise facility services firms (ABM, ISS, Sodexo, Aramark, CBRE/JLL
      IFM) seeking standardized QA at scale.
    - >-
      Independent/regional cleaning companies (10–50 cleaners) aiming to
      win/retain B2B contracts via quality differentiation.
    - >-
      In-house facilities teams at large enterprises, hospitals, universities,
      and public sector buildings.
    - >-
      Franchised cleaning brands that need consistent brand-level QA and
      reporting across franchisees.
  channels:
    - >-
      Direct sales to NAICS 561720 (Janitorial Services) via targeted outbound
      (email/LinkedIn) with case studies and ROI calculator.
    - >-
      Partnerships with janitorial and IFM software vendors (TEAM/WorkWave,
      Swept, Aspire, OrangeQC, iAuditor) for co-selling and marketplace
      listings.
    - >-
      Enterprise pilots via IFM integrators (ABM, ISS, Sodexo, Aramark) focusing
      on a vertical (e.g., healthcare or education) to standardize QA.
    - >-
      Industry events and associations: ISSA Show North America, BSCAI, IFMA;
      speaking slots and live demos.
    - >-
      Content-led inbound: “QA Score Benchmark Report,” checklists templates,
      and video demos; SEO for “janitorial QA software,” “cleaning audit app,”
      “facility QA reports.”
    - >-
      Referral program for regional cleaning firms; discounts for multi-site
      adoption.
    - >-
      Resellers/MSPs serving facilities; facility insurance brokers bundling QA
      to reduce claims.
    - >-
      Customer success-led land-and-expand: start with restrooms/high-complaint
      zones, then expand to full sites and chains.
  revenueStreams:
    - >-
      Per-location subscription (tiered): Basic $49/site/mo (up to 300 images),
      Pro $99/site/mo (adds video, integrations), Enterprise custom (SLA, SSO,
      volume discounts).
    - >-
      Usage-based overages: $0.002 per image, $0.005 per video second beyond
      plan limits.
    - >-
      Enterprise contracts: annual prepay, minimums, and professional services
      packages (implementation/training $3k–$25k).
    - >-
      Optional human review add-on for critical sites: $0.01–$0.03 per image
      equivalent.
    - White-label/reseller fees for software partners (10–30% revenue share).
    - >-
      Insights add-on: portfolio benchmarking and executive dashboards
      $10–$20/site/mo.
  costStructure:
    - >-
      Cloud inference and storage: target <$0.002 per image and <$0.005 per
      video second; average COGS per typical site $3–$5/mo (150 images + 300s
      video + storage).
    - >-
      Model training/labeling: initial dataset creation and ongoing annotation
      (Labelbox/Scale), budget $50k–$200k per model family annually.
    - >-
      Engineering and MLOps: 4–8 FTE for core product, inference optimization,
      and integrations.
    - 'Human-in-the-loop review team (variable, tied to add-on revenue).'
    - >-
      Sales and marketing: SDRs, AE commissions (10–12%), events (ISSA/IFMA),
      paid ads for niche keywords.
    - >-
      Customer success/onboarding: implementation managers for enterprise
      pilots.
    - >-
      Security/compliance: SOC 2 Type II audit, penetration tests, insurance
      (cyber/E&O).
    - >-
      General and administrative: legal (client data agreements/BAAs), finance,
      HR.
  keyMetrics:
    - >-
      Model performance: per-item precision ≥92%, recall ≥88% (restrooms ≥90%
      recall), false-positive rate ≤5% on high-priority items.
    - 'Time-to-score: median <60 seconds from upload to result; P95 <3 minutes.'
    - >-
      Upload compliance: >90% of required shifts submit media; late/missing rate
      trending down 5% month-over-month in first 90 days.
    - >-
      Quality outcomes: 20–40% reduction in client complaints within 3 months;
      25% reduction in supervisor site visits in 6 months.
    - >-
      Operational: issue resolution time (median <24h), recurrence of same issue
      reduced by 30% in 90 days.
    - >-
      Adoption: weekly active cleaners ≥70% of those assigned; ≥2 uploads per
      shift on targeted zones.
    - >-
      Business: Gross margin ≥75% (target 80%+), CAC payback <9 months, logo
      retention >90%, NRR ≥110%.
    - >-
      Sales funnel: outbound to meeting set rate ≥3%, meeting-to-pilot ≥30%,
      pilot-to-paid ≥60%, expansion within 6 months ≥40%.
    - >-
      Security/Compliance: 0 critical incidents; SOC 2 Type II achieved within
      12 months.
storyBrand:
  character: >-
    Janitorial owners and operations managers who must deliver consistent
    quality across sites and prove work to clients.
  problem: >-
    - External: Missed tasks, inconsistent results, and manual inspections that
    don’t scale.

    - Internal: Frustration over client complaints and lack of real-time
    visibility.

    - Philosophical: Clean spaces should be verifiably clean—evidence should be
    simple and objective.
  guide: >-
    - Empathy: We understand inspections are subjective, time-consuming, and
    hard to standardize.

    - Authority: Domain-trained computer vision aligned to janitorial
    checklists, privacy-first design, and clear, auditable QA evidence.
  plan: >-
    1) Configure sites and checklists. 2) Cleaners or clients upload
    photos/videos per area. 3) AI scores, flags misses, and compiles shareable
    QA reports with evidence, trends, and coaching cues.
  callToAction: |-
    - Direct: Start a pilot or book a 20‑minute demo.
    - Transitional: Download a sample QA report and checklist template.
  success: >-
    Objective QA scores by site, fewer callbacks, faster proof-of-work,
    standardized training, higher client trust, and stronger renewals.
  failure: >-
    Ongoing disputes, costly re-cleans, churned contracts, wasted supervisor
    hours, and guesswork instead of evidence.
landingPage:
  hero:
    title: AI QA Audits for Janitorial Services
    subtitle: >-
      Vision-based scoring from photo/video uploads. Catch misses, standardize
      quality, and send proof—automatically.
    ctaText: Get a Demo
    ctaHref: /demo
  problem:
    - Quality checks are inconsistent and time-consuming
    - Spot-inspections miss issues between visits
    - 'Client disputes lack clear, time-stamped proof'
    - Subjective scoring varies by inspector and site
    - Manual reports delay feedback and actions
    - No easy way to see trends across locations
  solution:
    - Turn every clean into an auditable record with visual evidence
    - 'Objective, checklist-based scoring—no clipboards or bias'
    - Automatic flags for missed or incomplete tasks
    - Shareable QA reports for clients and managers
    - Real-time alerts to fix issues before they become complaints
    - Trends and insights to coach teams and improve SLAs
  features:
    - Photo and short-video uploads from any device
    - AI compares evidence to your checklist and weights
    - Automatic missed-task flags with visual callouts
    - 'Time, location, and area tagging for each upload'
    - Standardized pass/fail and numeric scoring
    - One-click QA reports (link or PDF)
    - 'Multi-site dashboard, trends, and leaderboards'
    - Notifications to Slack/Email when scores drop
    - Role-based access for clients and staff
    - API/webhooks and CSV export for your systems
  steps:
    - Create or import your cleaning checklists
    - Cleaners or clients upload photos/videos at job completion
    - AI analyzes evidence and auto-scores against the checklist
    - 'Review flags, add notes, and request re-work if needed'
    - Send shareable QA reports to stakeholders
    - 'Track trends, coach your team, and improve compliance'
---
# CleanSight QA

Industry: Janitorial Services
Service: Photo/Video QA Audits with Automatic Scoring
