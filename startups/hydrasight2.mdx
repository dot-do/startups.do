---
name: >-
  HydraSight2 — EOL Test Data Automation & NCR Triage for Hydraulic Pump/Motor
  Manufacturing (NAICS 333996)
slug: hydrasight2
naics:
  primary: '333996'
  occupations: []
service:
  title: Automated EOL Test Report Summarization & NCR Triage
  description: >-
    Normalize raw test reports, compute KPIs, decide pass/fail, and open/route
    nonconformances.
  targetUsers:
    - Quality
    - Production test
    - Manufacturing engineering
  triggers:
    - New CSV/PDF test report exported
    - Daily batch folder sweep
  inputs:
    - 'Test reports (CSV, PDF, XLS)'
    - Control limits/spec sheets
    - Defect code taxonomy
    - QMS project info
  steps:
    - Parse/OCR reports and standardize schema
    - Compute volumetric/mechanical/overall efficiency and leakage at points
    - Decide pass/fail; map to defect codes
    - Draft NCR with probable cause and attachments
    - Notify owners; sync to QMS
  tools:
    - PDFPlumber/Tesseract
    - Python/Pandas
    - Rule engine + LLM for narrative
    - QMS API (ETQ/MasterControl/Sparta)
    - Email/Teams webhooks
  outputs:
    - Standardized digital test record
    - Pass/fail decision with rationale
    - NCR tickets with attachments
    - Pareto charts by defect
  pricingModel:
    - Per-report processing fee
    - Monthly platform fee
  humanInLoop: true
  feasibility:
    remoteOnLaptop: 9
    modelCapability: 8
    overall: 8.5
  risks:
    - OCR errors on scanned forms
    - Spec interpretation mistakes
    - QMS API rate limits
  dependencies:
    - Access to report export location
    - Up-to-date control limits
    - QMS integration credentials
leanCanvas:
  problem:
    - >-
      Unstructured EOL test data (PDFs/CSVs/DAq logs) consumes 2–6 minutes/test
      for manual review and data entry, creating bottlenecks at daily volumes of
      200–1,000 tests per plant.
    - >-
      Inconsistent KPI computation (e.g., volumetric/mechanical efficiency,
      leakage, pressure ripple) leads to 3–8% false fails or escapes due to unit
      mismatches, sampling rate differences, and misapplied spec limits.
    - >-
      NCRs are opened late or routed incorrectly; median NCR cycle time is 3–7
      days with 20–40% ping-pong between Quality, Test, and Assembly.
    - >-
      Root-cause triage is tribal-knowledge dependent; loss of senior
      technicians increases investigation time by 30–60 minutes/NCR and raises
      repeat issues.
    - >-
      No closed-loop from test results to QMS/MES; weak auditability for ISO
      9001/IATF 16949/AS9100 during PPAP/FAI runs and customer audits.
  solution:
    - >-
      Ingest raw test outputs from DAQ/PLC/CSV/PDF and normalize units/sampling
      into a canonical schema.
    - >-
      Compute domain KPIs: volumetric/mechanical efficiency, case drain flow,
      leakage rates, pressure ripple, temperature rise, noise, torque-speed
      curves, valve hysteresis.
    - >-
      Apply spec packs by part/revision/fixture; decide pass/fail with
      explainable rules + ML-based anomaly detection for borderline cases.
    - >-
      Auto-summarize test run and open NCRs for nonconforming units with likely
      root-cause classification and routing to responsible cell/team.
    - >-
      Sync results bi-directionally with QMS/MES/ERP (e.g., SAP QM, Plex, ETQ)
      and maintain audit-ready traceability and electronic signatures.
    - >-
      Provide live dashboards, SPC, alerting, and model/rule governance (change
      control, approvals, versioning).
  uniqueValueProp: >-
    Automate EOL report normalization, KPI computation, pass/fail decisions, and
    NCR triage—cut NCR cycle time by 50%, reduce false failures by 60%, and lift
    first-pass yield 3–7% with auditable, domain-specific AI that runs at the
    edge or on-prem.
  unfairAdvantage: >-
    Proprietary hydraulics-specific KPI/limits library and labeled triage
    dataset collected via integrator/OEM partnerships; validated connectors to
    dominant test benches; audit-grade decisioning with explainability tailored
    to fluid power—difficult for generic AI or horizontal IIoT platforms to
    replicate quickly.
  customerSegments:
    - >-
      Primary: Fluid power pump and motor OEMs (NAICS 333996), 50–5,000
      employees, EOL test on every production unit.
    - >-
      Secondary: Contract manufacturers/remanufacturers of hydraulic components
      with in-house test stands.
    - >-
      Internal champions: Quality managers, Test engineering managers,
      Manufacturing engineering, Plant managers.
    - >-
      Influencers/partners: Test stand OEMs/integrators, NI/LabVIEW/TestStand
      developers, QMS/MES/ERP admins.
  channels:
    - >-
      Direct sales to Quality/Test/Operations leaders at fluid power OEMs in US
      Midwest and Southeast.
    - >-
      Alliances with test stand OEMs/integrators and NI Alliance Partners to
      bundle during new stand installs/upgrades.
    - >-
      Industry associations and events: NFPA, IFPE/CONEXPO, Fluid Power
      Technology Conference; technical webinars and case studies.
    - >-
      Targeted ABM campaigns to 200 priority plants; ROI calculator and pilot
      program.
    - >-
      Referral program for integrators and manufacturing consultants (10–15%
      first-year revenue share).
  revenueStreams:
    - >-
      Annual subscription per connected test stand: $1,500–$3,000/month/stand
      depending on features and volume.
    - >-
      Enterprise license: tiered by plants/stands (e.g., $150k–$400k/year)
      including unlimited users and centralized governance.
    - >-
      Usage-based add-on: $0.02–$0.05 per processed test beyond included quota
      for high-volume lines.
    - >-
      Professional services: integration, spec migration, validation (IQ/OQ/PQ),
      and training at $180–$240/hour or fixed packages ($25k–$120k).
    - >-
      Premium compliance pack: audit bundles, advanced e-signatures, and
      retention policies ($25k/year).
    - >-
      Support/SLA tiers: standard included; premium 24/7 with on-site spares and
      <2h response (+$30k–$60k/year).
  costStructure:
    - >-
      R&D: ML/controls engineers, test domain SMEs, software engineers
      ($3–5M/year at scale).
    - >-
      Sales/marketing: account execs, technical pre-sales, events, content
      ($1–2M/year).
    - >-
      Professional services and customer success: deployment engineers, trainers
      ($1–2M/year, partially offset by services revenue).
    - >-
      Infrastructure: cloud services for management/telemetry, CI/CD, artifact
      registries ($200–500k/year); edge hardware is customer-provided.
    - >-
      Security/compliance: SOC 2/ISO 27001 audits, penetration testing,
      insurance ($200–400k/year).
    - >-
      Partner/channel costs: referral fees, co-marketing, certifications
      ($100–300k/year).
  keyMetrics:
    - >-
      Operational impact: FPY uplift (+3–7% within 6 months), NCR cycle time
      reduction (baseline median days vs target -50%), rework/scrap cost
      reduction (10–20%).
    - >-
      Automation accuracy: auto pass/fail accuracy ≥99.5% against validated spec
      rules; false fail rate ≤0.5%; triage precision ≥80%, recall ≥85%.
    - >-
      Throughput/time saved: manual report handling cut from 3–5 min/test to <15
      sec/test; technician hours saved per 1,000 tests (>45 hours).
    - >-
      Adoption: connected stands, % tests auto-processed (>95%), DAUs among
      engineers, % NCRs auto-routed (>85%).
    - >-
      Reliability: data ingestion success rate ≥99.9%, edge uptime ≥99.5%, mean
      time to detect ingest failure <2 min.
    - >-
      Compliance: 100% audit trail completeness; change control approvals within
      SLA; number of audit findings related to test data = 0.
    - >-
      Business: gross margin on software >80%, logo retention >95%, NRR ≥120%,
      sales cycle length <120 days, pilot-to-production conversion >70%.
storyBrand:
  character: >-
    Quality, Test, and Operations leaders at fluid power pump and motor
    manufacturers (NAICS 333996) who need fast, accurate EOL decisions to keep
    takt, protect customers, and control cost of quality.
  problem: >-
    Disparate raw test files and inconsistent limits force manual review;
    pass/fail calls are late or inconsistent; NCRs languish in inboxes; KPIs are
    hidden—driving delays, escapes, rework, and audit pain.
  guide: >-
    We understand hydraulics EOL and ISO-driven quality. Our AI normalizes bench
    outputs, applies domain rules for pressure/flow/leakage/efficiency, and
    integrates with MES/QMS/ERP—securely on‑prem or in your VPC.
  plan: >-
    1) Connect test stands and data stores. 2) Configure normalization, KPIs,
    and pass/fail rules. 3) Pilot on one product family in shadow mode to
    validate. 4) Go live: auto-summarize reports, decide pass/fail, and
    open/route NCRs with dashboards and alerts. Low-risk, fixed-scope pilot;
    cancel anytime.
  callToAction: Schedule a 30‑minute demo or start a 30‑day pilot.
  success: >-
    Instant, audit-ready test summaries; consistent pass/fail; automatic NCR
    creation and routing; faster closure; higher FPY and OEE; fewer escapes;
    on-time shipments; lower cost of quality.
  failure: >-
    Keep firefighting: slow decisions, NCR backlog, missed ship dates, repeat
    defects, warranty exposure, and tough audits.
landingPage:
  hero:
    title: Automate EOL Test Reports and NCR Triage
    subtitle: >-
      AI for Fluid Power Pump & Motor Manufacturing (NAICS 333996). Normalize
      test data, compute KPIs, decide pass/fail, and route nonconformances—fast,
      consistent, auditable.
    ctaText: Book a demo
    ctaHref: /demo
  problem:
    - >-
      Raw EOL reports live in CSVs, PDFs, and screenshots—hard to trust or
      reuse.
    - Engineers spend hours parsing plots and deciding pass/fail by hand.
    - 'Spec checks vary by person, shift, and product revision.'
    - 'NCRs open late or route to the wrong owners, slowing containment.'
    - Traceability from test plan to serial number is fragmented.
    - 'Late decisions drive rework, WIP buildup, and missed ship dates.'
    - Audits stall on missing evidence and inconsistent rationale.
  solution:
    - 'Normalize raw test data into a clean, searchable model.'
    - >-
      Compute KPIs per test plan: flow, pressure, leakage, efficiency,
      temperature, noise, torque.
    - 'Apply limits and tolerances by part number, customer, and revision.'
    - Auto pass/fail with reason codes and highlighted out-of-bounds steps.
    - >-
      Open NCRs with prefilled context; route to Quality, ME, Test, or Supplier
      Quality.
    - Notify via Teams/Email and track SLA to closure.
    - >-
      Deliver concise summaries for operators and deep drill-downs for
      engineers.
    - Maintain full traceability and an auditable decision trail.
  features:
    - >-
      Plug-and-play connectors: NI/LabVIEW exports, PLC/stand CSV, SQL, REST,
      OPC UA, PDF OCR.
    - >-
      Schema mapping for part number, serial, work order, test plan rev,
      operator, fixture, shift.
    - >-
      Time-series processing: filtering, steady-state windows, peaks/plateaus,
      ramp segments.
    - KPI library and custom formulas with unit normalization (metric/imperial).
    - >-
      Rules engine for pass/fail: spec bands, guard bands, hysteresis,
      multi-step sequences.
    - >-
      Variant management: limits by PN/rev/customer and test plan version
      control.
    - 'Anomaly and drift detection across lots, lines, and shifts.'
    - >-
      Automated NCR creation with templates, reason code suggestions, and
      containment prompts.
    - >-
      Routing rules by cell, product line, supplier, or threshold severity; SLA
      timers.
    - >-
      Integrations via API/webhooks to QMS/ERP/MES (e.g., SAP, Oracle, Plex,
      Epicor, Arena).
    - >-
      Dashboards: FPY, top failure modes, trend charts, Cpk/Ppk, NCR cycle time
      and backlog.
    - 'Role-based access, SSO, and detailed audit logs with e-sign approvals.'
    - >-
      Deployment options: secure cloud or on‑prem; minimal footprint in OT
      networks.
    - 'Data retention policies, bulk export, and PDF summary generation per unit.'
    - >-
      Multi-plant readiness: tenant and site segregation; localization of UI and
      units.
    - >-
      Enterprise-grade security: encryption in transit/at rest and granular
      permissions.
  steps:
    - Connect your test stand data sources and sample reports.
    - 'Map fields to the canonical schema (PN, serial, plan rev, units).'
    - Import spec limits and tolerances per part and revision.
    - Validate on historical runs; tune KPIs and rules with engineers.
    - 'Go live: auto summarize results, decide pass/fail, and open/route NCRs.'
    - 'Monitor dashboards, adjust thresholds, and lock workflows for audit.'
    - 'Scale to additional lines, products, and plants.'
---
# HydraSight2 — EOL Test Data Automation & NCR Triage for Hydraulic Pump/Motor Manufacturing (NAICS 333996)

Generated for NAICS 333996 — Fluid Power Pump and Motor Manufacturing.
Service: EOL Test Data Automation & NCR Triage

## Business-as-Code Workflow Functions

```typescript
// Customer Acquisition Workflows
export async function acquireCustomer(lead: FluidPowerLead): Promise<Customer> {
  const qualifiedLead = await qualifyFluidPowerLead(lead)
  const technicalAssessment = await conductTechnicalAssessment(qualifiedLead)
  const pilot = await proposePilotProgram(technicalAssessment)
  const contract = await negotiateEnterpriseContract(pilot)
  return await onboardCustomer(contract)
}

export async function qualifyFluidPowerLead(lead: FluidPowerLead): Promise<QualifiedLead> {
  const criteria = {
    naicsCode: '333996',
    employeeCount: { min: 50, max: 5000 },
    hasEOLTesting: true,
    testVolume: { min: 200, max: 1000 }, // tests per day
    currentPainPoints: ['manual_data_entry', 'false_failures', 'ncr_delays']
  }
  
  if (await validateCriteria(lead, criteria)) {
    const stakeholders = await identifyStakeholders(lead)
    return await createQualifiedLead(lead, stakeholders)
  }
  
  throw new Error('Lead does not meet qualification criteria')
}

export async function conductTechnicalAssessment(lead: QualifiedLead): Promise<TechnicalAssessment> {
  const currentState = await assessCurrentTestingProcess(lead)
  const integrationPoints = await identifyIntegrationPoints(lead)
  const roiProjection = await calculateROIProjection(currentState)
  
  return {
    currentState,
    integrationPoints,
    roiProjection,
    recommendedSolution: await designSolutionArchitecture(currentState, integrationPoints)
  }
}

// Product Development Processes
export async function developHydraulicKPILibrary(): Promise<KPILibrary> {
  const domainExperts = await recruitHydraulicsExperts()
  const testData = await collectHistoricalTestData()
  const kpiDefinitions = await defineHydraulicKPIs(domainExperts, testData)
  
  return await validateKPILibrary(kpiDefinitions)
}

export async function defineHydraulicKPIs(experts: DomainExpert[], data: TestData[]): Promise<KPIDefinition[]> {
  return [
    await defineVolumetricEfficiency(experts, data),
    await defineMechanicalEfficiency(experts, data),
    await defineCaseDrainFlow(experts, data),
    await defineLeakageRates(experts, data),
    await definePressureRipple(experts, data),
    await defineTemperatureRise(experts, data),
    await defineNoiseMetrics(experts, data),
    await defineTorqueSpeedCurves(experts, data),
    await defineValveHysteresis(experts, data)
  ]
}

export async function developMLAnomalyDetection(): Promise<AnomalyDetectionModel> {
  const trainingData = await collectLabeledTestData()
  const features = await extractHydraulicFeatures(trainingData)
  const model = await trainAnomalyModel(features)
  
  return await validateModelAccuracy(model, { precision: 0.8, recall: 0.85 })
}

// Revenue Generation Flows
export async function generateRevenue(customer: Customer): Promise<RevenueStream[]> {
  const subscriptionRevenue = await processSubscriptionBilling(customer)
  const servicesRevenue = await deliverProfessionalServices(customer)
  const usageRevenue = await processUsageBasedCharges(customer)
  
  return [subscriptionRevenue, servicesRevenue, usageRevenue]
}

export async function processSubscriptionBilling(customer: Customer): Promise<SubscriptionRevenue> {
  const connectedStands = await getConnectedTestStands(customer)
  const tierPricing = await calculateTierPricing(connectedStands.length)
  
  return await generateInvoice({
    customer,
    amount: tierPricing.monthlyAmount,
    description: `${connectedStands.length} test stands @ ${tierPricing.pricePerStand}/month`,
    billingPeriod: 'monthly'
  })
}

export async function deliverProfessionalServices(customer: Customer): Promise<ServicesRevenue> {
  const services = [
    await performSystemIntegration(customer),
    await conductSpecMigration(customer),
    await deliverValidationServices(customer),
    await provideTraining(customer)
  ]
  
  return await billProfessionalServices(services)
}

// Operational Procedures
export async function processEOLTestData(testData: RawTestData): Promise<ProcessedTestResult> {
  const normalizedData = await normalizeTestData(testData)
  const kpis = await computeHydraulicKPIs(normalizedData)
  const decision = await makePassFailDecision(kpis)
  
  if (decision.result === 'FAIL') {
    await generateNCR(decision, normalizedData)
  }
  
  return await syncWithQMS(decision, normalizedData)
}

export async function normalizeTestData(rawData: RawTestData): Promise<NormalizedTestData> {
  const schema = await getCanonicalSchema(rawData.testType)
  const unitConverter = await createUnitConverter()
  const samplingNormalizer = await createSamplingNormalizer()
  
  return {
    testId: rawData.testId,
    partNumber: rawData.partNumber,
    serialNumber: rawData.serialNumber,
    measurements: await normalizeMeasurements(rawData.measurements, unitConverter),
    samplingRate: await normalizeSamplingRate(rawData.samplingRate, samplingNormalizer),
    timestamp: rawData.timestamp,
    testStandId: rawData.testStandId
  }
}

export async function computeHydraulicKPIs(data: NormalizedTestData): Promise<HydraulicKPIs> {
  const kpiLibrary = await getKPILibrary()
  
  return {
    volumetricEfficiency: await kpiLibrary.computeVolumetricEfficiency(data),
    mechanicalEfficiency: await kpiLibrary.computeMechanicalEfficiency(data),
    caseDrainFlow: await kpiLibrary.computeCaseDrainFlow(data),
    leakageRates: await kpiLibrary.computeLeakageRates(data),
    pressureRipple: await kpiLibrary.computePressureRipple(data),
    temperatureRise: await kpiLibrary.computeTemperatureRise(data),
    noiseLevel: await kpiLibrary.computeNoiseLevel(data),
    torqueSpeedCurve: await kpiLibrary.computeTorqueSpeedCurve(data),
    valveHysteresis: await kpiLibrary.computeValveHysteresis(data)
  }
}

export async function makePassFailDecision(kpis: HydraulicKPIs): Promise<TestDecision> {
  const specLimits = await getSpecLimits(kpis.partNumber, kpis.revision)
  const ruleBasedDecision = await applySpecRules(kpis, specLimits)
  
  if (ruleBasedDecision.confidence < 0.9) {
    const mlDecision = await applyMLAnomalyDetection(kpis)
    return await reconcileDecisions(ruleBasedDecision, mlDecision)
  }
  
  return ruleBasedDecision
}

// Decision-Making Workflows
export async function triageNCR(ncr: NCR): Promise<TriagedNCR> {
  const rootCauseAnalysis = await performRootCauseAnalysis(ncr)
  const responsibleTeam = await determineResponsibleTeam(rootCauseAnalysis)
  const priority = await calculatePriority(ncr, rootCauseAnalysis)
  
  return await routeNCR(ncr, responsibleTeam, priority)
}

export async function performRootCauseAnalysis(ncr: NCR): Promise<RootCauseAnalysis> {
  const historicalData = await getHistoricalNCRData(ncr.partNumber)
  const testConditions = await analyzeTestConditions(ncr.testData)
  const componentAnalysis = await analyzeComponentFailures(ncr.failedKPIs)
  
  const mlClassification = await classifyRootCause({
    historicalData,
    testConditions,
    componentAnalysis,
    failurePattern: ncr.failurePattern
  })
  
  return {
    primaryCause: mlClassification.primaryCause,
    contributingFactors: mlClassification.contributingFactors,
    confidence: mlClassification.confidence,
    recommendedActions: await generateRecommendedActions(mlClassification)
  }
}

export async function determineResponsibleTeam(analysis: RootCauseAnalysis): Promise<ResponsibleTeam> {
  const teamMapping = {
    'assembly_issue': 'Assembly',
    'component_defect': 'Quality',
    'test_setup_error': 'Test Engineering',
    'design_issue': 'Engineering',
    'supplier_issue': 'Supply Chain'
  }
  
  return teamMapping[analysis.primaryCause] || 'Quality'
}

export async function monitorQualityMetrics(): Promise<QualityDashboard> {
  const realTimeMetrics = await collectRealTimeMetrics()
  const spcCharts = await generateSPCCharts(realTimeMetrics)
  const alerts = await checkQualityAlerts(realTimeMetrics)
  
  return {
    firstPassYield: realTimeMetrics.fpy,
    ncrCycleTime: realTimeMetrics.ncrCycleTime,
    falseFailureRate: realTimeMetrics.falseFailureRate,
    testThroughput: realTimeMetrics.testThroughput,
    spcCharts,
    alerts,
    lastUpdated: new Date()
  }
}

// Integration Workflows
export async function syncWithQMS(decision: TestDecision, data: NormalizedTestData): Promise<QMSRecord> {
  const qmsConnector = await getQMSConnector(data.plantId)
  
  const record = {
    testId: data.testId,
    partNumber: data.partNumber,
    serialNumber: data.serialNumber,
    testResult: decision.result,
    kpis: decision.kpis,
    timestamp: data.timestamp,
    electronicSignature: await generateElectronicSignature(decision, data),
    auditTrail: await createAuditTrail(decision, data)
  }
  
  return await qmsConnector.createQualityRecord(record)
}

export async function maintainAuditTrail(action: QualityAction): Promise<AuditRecord> {
  return {
    actionId: generateUUID(),
    timestamp: new Date(),
    userId: action.userId,
    actionType: action.type,
    entityId: action.entityId,
    changes: action.changes,
    electronicSignature: await generateElectronicSignature(action),
    complianceFlags: await checkComplianceRequirements(action)
  }
}

// Recurring Workflows
export async function every(interval: string, workflow: WorkflowFunction): Promise<ScheduledWorkflow> {
  return await scheduleRecurringWorkflow(interval, workflow)
}

export async function on(event: string, handler: EventHandler): Promise<EventSubscription> {
  return await subscribeToEvent(event, handler)
}

// Example scheduled workflows
export const dailyQualityReport = every('day', async ({ ai, db }) => {
  const metrics = await monitorQualityMetrics()
  const report = await ai.generateText(`Generate daily quality report based on: ${JSON.stringify(metrics)}`)
  await db.reports.create({ type: 'daily_quality', content: report, date: new Date() })
})

export const weeklyNCRReview = every('week', async ({ ai, db }) => {
  const openNCRs = await db.ncrs.findMany({ status: 'OPEN' })
  const analysis = await ai.generateObject({
    prompt: `Analyze open NCRs for trends and recommendations: ${JSON.stringify(openNCRs)}`,
    schema: { trends: 'string[]', recommendations: 'string[]', priorityActions: 'string[]' }
  })
  await db.reports.create({ type: 'weekly_ncr_review', content: analysis, date: new Date() })
})

// Event-driven workflows
export const onTestCompletion = on('EOLTest.Completed', async (event, { ai, db }) => {
  const testResult = await processEOLTestData(event.data)
  if (testResult.decision.result === 'FAIL') {
    await triageNCR(testResult.ncr)
  }
  await updateQualityDashboard(testResult)
})

export const onNCRCreated = on('NCR.Created', async (event, { ai, db }) => {
  const ncr = event.data
  const triaged = await triageNCR(ncr)
  await notifyResponsibleTeam(triaged)
  await updateNCRMetrics(triaged)
})
```

## Type Definitions

```typescript
interface FluidPowerLead {
  companyName: string
  naicsCode: string
  employeeCount: number
  contactInfo: ContactInfo
  testingVolume: number
  currentChallenges: string[]
}

interface QualifiedLead extends FluidPowerLead {
  stakeholders: Stakeholder[]
  qualificationScore: number
  nextSteps: string[]
}

interface TechnicalAssessment {
  currentState: CurrentStateAnalysis
  integrationPoints: IntegrationPoint[]
  roiProjection: ROIProjection
  recommendedSolution: SolutionArchitecture
}

interface RawTestData {
  testId: string
  partNumber: string
  serialNumber: string
  testType: string
  measurements: Record<string, number>
  samplingRate: number
  timestamp: Date
  testStandId: string
}

interface NormalizedTestData {
  testId: string
  partNumber: string
  serialNumber: string
  measurements: Record<string, number>
  samplingRate: number
  timestamp: Date
  testStandId: string
  plantId?: string
}

interface HydraulicKPIs {
  volumetricEfficiency: number
  mechanicalEfficiency: number
  caseDrainFlow: number
  leakageRates: number[]
  pressureRipple: number
  temperatureRise: number
  noiseLevel: number
  torqueSpeedCurve: TorqueSpeedPoint[]
  valveHysteresis: number
  partNumber: string
  revision: string
}

interface TestDecision {
  result: 'PASS' | 'FAIL' | 'RETEST'
  confidence: number
  kpis: HydraulicKPIs
  failedParameters: string[]
  reasoning: string
  timestamp: Date
}

interface NCR {
  ncrId: string
  partNumber: string
  serialNumber: string
  testData: NormalizedTestData
  failedKPIs: string[]
  failurePattern: string
  createdAt: Date
  status: 'OPEN' | 'IN_PROGRESS' | 'CLOSED'
}

interface TriagedNCR extends NCR {
  rootCauseAnalysis: RootCauseAnalysis
  responsibleTeam: ResponsibleTeam
  priority: Priority
  routedAt: Date
}

interface RootCauseAnalysis {
  primaryCause: string
  contributingFactors: string[]
  confidence: number
  recommendedActions: string[]
}

interface QualityDashboard {
  firstPassYield: number
  ncrCycleTime: number
  falseFailureRate: number
  testThroughput: number
  spcCharts: SPCChart[]
  alerts: QualityAlert[]
  lastUpdated: Date
}

interface ProcessedTestResult {
  decision: TestDecision
  normalizedData: NormalizedTestData
  ncr?: NCR
  qmsRecord: QMSRecord
}

interface Customer {
  customerId: string
  companyName: string
  industry: string
  contractDetails: ContractDetails
  connectedStands: TestStand[]
}

interface RevenueStream {
  type: 'subscription' | 'services' | 'usage'
  amount: number
  period: string
  description: string
}

interface KPILibrary {
  computeVolumetricEfficiency: (data: NormalizedTestData) => Promise<number>
  computeMechanicalEfficiency: (data: NormalizedTestData) => Promise<number>
  computeCaseDrainFlow: (data: NormalizedTestData) => Promise<number>
  computeLeakageRates: (data: NormalizedTestData) => Promise<number[]>
  computePressureRipple: (data: NormalizedTestData) => Promise<number>
  computeTemperatureRise: (data: NormalizedTestData) => Promise<number>
  computeNoiseLevel: (data: NormalizedTestData) => Promise<number>
  computeTorqueSpeedCurve: (data: NormalizedTestData) => Promise<TorqueSpeedPoint[]>
  computeValveHysteresis: (data: NormalizedTestData) => Promise<number>
}

interface AnomalyDetectionModel {
  predict: (kpis: HydraulicKPIs) => Promise<AnomalyPrediction>
  retrain: (data: TestData[]) => Promise<void>
  accuracy: ModelAccuracy
}

interface QMSRecord {
  recordId: string
  testId: string
  partNumber: string
  serialNumber: string
  testResult: string
  kpis: HydraulicKPIs
  timestamp: Date
  electronicSignature: string
  auditTrail: AuditRecord[]
}

interface AuditRecord {
  actionId: string
  timestamp: Date
  userId: string
  actionType: string
  entityId: string
  changes: Record<string, any>
  electronicSignature: string
  complianceFlags: string[]
}

interface QualityAction {
  userId: string
  type: string
  entityId: string
  changes: Record<string, any>
}

type ResponsibleTeam = 'Assembly' | 'Quality' | 'Test Engineering' | 'Engineering' | 'Supply Chain'
type Priority = 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL'

interface WorkflowFunction {
  (context: { ai: any, db: any }): Promise<void>
}

interface EventHandler {
  (event: any, context: { ai: any, db: any }): Promise<void>
}

interface ScheduledWorkflow {
  id: string
  interval: string
  workflow: WorkflowFunction
  nextRun: Date
}

interface EventSubscription {
  id: string
  event: string
  handler: EventHandler
  active: boolean
}
```
